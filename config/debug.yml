seed: 1000000009
debug-log: yes

##############

#_meta.script_name: backend
#_base: [games]

##############

_meta.script_name: eval

# _base: [demo]
#_base: [s/dp, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/zcot, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/dp, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/dpp, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/dpp, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/manual, c/vllm]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/client, c/vllm]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/format, c/vllm]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/client, c/azure]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/client, c/vllm]

#_base: [s/zshot, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/zcot, ttt/take-the-middle, j/client, c/vllm, basic-view]
#_base: [s/fs, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/mv, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/cot, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/tool, ttt/tools, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/oracle-tool, ttt/tools, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/oracle-tool, ttt/tools, ttt/take-the-middle, j/format, c/vllm, basic-view]
#_base: [s/zshot, ttt/take-the-middle, j/format, c/azure]

#obs-rep: compact
##obs-rep: moves

#_base: [s/dpp, ttt/take-the-middle, j/format, c/vllm]

##################

_base: [s/zshot, chess/puzzle, j/format, c/vllm, basic-view]

obs-rep: fen
hint: all

##############
use-chat-completion: no
#tool-style: json

limit: 10

use-wandb: no

root: local_data/debug

#no-think: yes
#temperature: 1.0
#n-votes: 3

# for format judge: j/format
#style: end

#addr: http://wagner.is.localnet:8000
addr: 8001
#client.addr: 8001
#judge.addr: 8001


# resume: p6088_sfaa9_250515-120654_0b0d

#client._mod.logged: yes

#max-tokens: 1024
#max-tokens: 4096 # needed for qwen3-8b due to reasoning
#max-tokens: 1024

#temperature: 0.6
#top-p: 0.95


##################

# _base: [venice-sent, c/vllm]

# #template: venice/analysis
# template: venice/analysis-yaml

#############################
#
#_base: [1step, c/vllm]
##_base: [1step, c/openai]
##judge.template: judge-binary-nothink
#
##protocol.name: "{task.domain}-{judge.format_type}-{judge.pred_type}-{'_'.join(task.clues)}"
##protocol.name: "{task.domain}_{judge.format_type}_{judge.pred_type}_{'-'.join(task.clues)}_{now.strftime('%y%m%d-%H%M%S')}"
#
#protocol.name: "debug_{task.domain}_{judge.name}_{'-'.join(task.clues)}_{now.strftime('%y%m%d-%H%M%S')}_{unique[:4]}"
#
#
##resume: food_1step-json-prob_profile-responses-behavior_250511-133413
#
##resume: food_1step-json-prob_update2_250511-211320
#
#domain: news
##clues: [profile, responses, behavior]
#clues: [update2]
#
##zero-based: yes
##indexed: yes
#
##template: "{task_context}\n\n{question}\n/nothink"
##strategy.template: "{question}"
#
##pred-type: binary

