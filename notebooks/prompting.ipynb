{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b380d68c231be410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:27:48.942879Z",
     "start_time": "2025-08-05T10:27:45.756374Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if '_fixed' not in locals():\n",
    "    _fixed = os.chdir(os.path.dirname(os.getcwd()))\n",
    "import json\n",
    "import omnifig as fig\n",
    "from tqdm.notebook import tqdm\n",
    "from ludwig.util import PromptTemplate\n",
    "from ludwig.tictactoe import TakeTheMiddle\n",
    "from ludwig.util import vllm_Client\n",
    "from ludwig.util.clients import SAIA_Client\n",
    "from ludwig.util import extract_code_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f4d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CREATING . type='saia'\n",
      "| model: None (by default)\n",
      "| use-chat-completion: False (by default)\n",
      "| tool-style: 'pythonic' (by default)\n",
      "| chat-template-path: None (by default)\n",
      "| chat-template: None (by default)\n",
      "| enable-thinking: False (by default)\n",
      "| add-generation-prompt: True (by default)\n",
      "| continue-final-message: False (by default)\n",
      "| max-tokens: None (by default)\n",
      "| seed: None (by default)\n",
      "| temperature: None (by default)\n",
      "| top-p: None (by default)\n",
      "| grammar: None (by default)\n",
      "| raise-length-limit: True (by default)\n",
      "| system-message: None (by default)\n",
      "| message-parser: None (by default)\n",
      "| debug-log: False (by default)\n"
     ]
    }
   ],
   "source": [
    "client = fig.create_config('secrets/saia', _type='saia', model_name=None).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42506c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'meta-llama-3.1-8b-instruct',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Meta Llama 3.1 8B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'openai-gpt-oss-120b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'OpenAI GPT OSS 120B',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'gemma-3-27b-it',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text', 'image'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Gemma 3 27B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'qwen3-32b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text', 'thought'],\n",
       "  'name': 'Qwen 3 32B',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'qwen3-235b-a22b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text', 'thought'],\n",
       "  'name': 'Qwen 3 235B A22B 2507',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'llama-3.3-70b-instruct',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Meta Llama 3.3 70B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'qwen2.5-vl-72b-instruct',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text', 'image', 'video'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Qwen 2.5 VL 72B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'medgemma-27b-it',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text', 'image'],\n",
       "  'output': ['text'],\n",
       "  'name': 'MedGemma 27B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'qwq-32b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text', 'thought'],\n",
       "  'name': 'Qwen QwQ 32B',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'deepseek-r1',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text', 'thought'],\n",
       "  'name': 'DeepSeek R1 0528',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'deepseek-r1-distill-llama-70b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text', 'thought'],\n",
       "  'name': 'DeepSeek R1 Distill Llama 70B',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'mistral-large-instruct',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Mistral Large Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'qwen2.5-coder-32b-instruct',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Qwen 2.5 Coder 32B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'internvl2.5-8b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text', 'image'],\n",
       "  'output': ['text'],\n",
       "  'name': 'InternVL2.5 8B MPO',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'teuken-7b-instruct-research',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Teuken 7B Instruct Research',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'codestral-22b',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Codestral 22B',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'llama-3.1-sauerkrautlm-70b-instruct',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text', 'arcana'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Llama 3.1 SauerkrautLM 70B Instruct',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'},\n",
       " {'id': 'meta-llama-3.1-8b-rag',\n",
       "  'created': 1755111540,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'chat-ai',\n",
       "  'input': ['text', 'arcana'],\n",
       "  'output': ['text'],\n",
       "  'name': 'Meta Llama 3.1 8B RAG',\n",
       "  'demand': 0,\n",
       "  'status': 'ready'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = client.available_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee3e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------  -----------------------------------\n",
      "meta-llama-3.1-8b-instruct           Meta Llama 3.1 8B Instruct\n",
      "openai-gpt-oss-120b                  OpenAI GPT OSS 120B\n",
      "gemma-3-27b-it                       Gemma 3 27B Instruct\n",
      "qwen3-32b                            Qwen 3 32B\n",
      "qwen3-235b-a22b                      Qwen 3 235B A22B 2507\n",
      "llama-3.3-70b-instruct               Meta Llama 3.3 70B Instruct\n",
      "qwen2.5-vl-72b-instruct              Qwen 2.5 VL 72B Instruct\n",
      "medgemma-27b-it                      MedGemma 27B Instruct\n",
      "qwq-32b                              Qwen QwQ 32B\n",
      "deepseek-r1                          DeepSeek R1 0528\n",
      "deepseek-r1-distill-llama-70b        DeepSeek R1 Distill Llama 70B\n",
      "mistral-large-instruct               Mistral Large Instruct\n",
      "qwen2.5-coder-32b-instruct           Qwen 2.5 Coder 32B Instruct\n",
      "internvl2.5-8b                       InternVL2.5 8B MPO\n",
      "teuken-7b-instruct-research          Teuken 7B Instruct Research\n",
      "codestral-22b                        Codestral 22B\n",
      "llama-3.1-sauerkrautlm-70b-instruct  Llama 3.1 SauerkrautLM 70B Instruct\n",
      "meta-llama-3.1-8b-rag                Meta Llama 3.1 8B RAG\n",
      "-----------------------------------  -----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate([x['id'], x['name']] for x in models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e3bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"meta-llama-3.1-8b-instruct\" # Choose any available model\n",
    "model = 'openai-gpt-oss-120b'\n",
    "  \n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key = fig.create_config('secrets/saia').pull('api-key', silent=True),\n",
    "    base_url = base_url\n",
    ")\n",
    "  \n",
    "# Get response\n",
    "chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"How tall is the Eiffel tower?\"}],\n",
    "        model= model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6375dfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-751d6b76a40b438080ba89516c9a9630',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'The Eiffel\\u202fTower stands **324\\u202fm** tall (about **1,063\\u202fft**) when you include its antenna.  \\n- Height to the roof (the top of the iron structure) is **300\\u202fm** (≈\\u202f984\\u202fft).  \\n- It was originally completed in 1889 at 312\\u202fm (≈\\u202f1,024\\u202fft) before the radio antenna was added.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'annotations': None,\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': [],\n",
       "    'reasoning_content': 'The user asks: \"How tall is the Eiffel tower?\" Straightforward question. Provide height in meters and feet. Perhaps mention different heights (original, to top, etc.). Answer concisely.'},\n",
       "   'stop_reason': None}],\n",
       " 'created': 1755077914,\n",
       " 'model': 'openai-gpt-oss-120b',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 134,\n",
       "  'prompt_tokens': 87,\n",
       "  'total_tokens': 221,\n",
       "  'prompt_tokens_details': None},\n",
       " 'prompt_logprobs': None,\n",
       " 'kv_transfer_params': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b9f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower stands **324 m** tall (about **1,063 ft**) when you include its antenna.  \n",
      "- Height to the roof (the top of the iron structure) is **300 m** (≈ 984 ft).  \n",
      "- It was originally completed in 1889 at 312 m (≈ 1,024 ft) before the radio antenna was added.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53690f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eba06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5edc31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981c48bde61b841f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:26:13.701004100Z",
     "start_time": "2025-08-05T10:11:50.027825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = TakeTheMiddle(obs_rep='moves')\n",
    "task.prepare()\n",
    "task.total_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fec5e62b177aea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:26:13.703546600Z",
     "start_time": "2025-08-05T10:13:10.547378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-3.3-70B-Instruct'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = vllm_Client(addr='8002').prepare()\n",
    "client.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9eb8d1e4dae7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = {\n",
    "\t'task': task.description(),\n",
    "\t'context': task.context(),\n",
    "}\n",
    "\n",
    "ctx['task'] = \"We're playing tic-tac-toe, and, given the current game state, I have a question about whether I should play in the middle or not.\"\n",
    "\n",
    "samples = [task.ask_dev(i) for i in range(10)]\n",
    "ctx.update({f'{key}{i}': value for i, sample in enumerate(samples) for key, value in sample.items()})\n",
    "samples[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcf071aaa159ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35449430a3e30292",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate('perception/design')\n",
    "# template.ident\n",
    "print(template.fill(**ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bbbc052e7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[1]['board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2b4c1b0599381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tranlation = '''\n",
    "Lastly, for each sample problem, provide the corresponding JSON formalization based on your schema. Ensure that the JSON representations are valid and adhere to the schema you propose.\n",
    "'''\n",
    "\n",
    "rep = '''{\n",
    "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "  \"title\": \"TicTacToeGameState\",\n",
    "  \"description\": \"Represents the state of a Tic Tac Toe game.\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"board\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"The Tic Tac Toe board represented as a 3x3 array. 'X' for Alice, 'O' for the player, and null for empty cells.\",\n",
    "      \"items\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": [\"string\", \"null\"],\n",
    "          \"enum\": [\"X\", \"O\", null]\n",
    "        },\n",
    "        \"minItems\": 3,\n",
    "        \"maxItems\": 3\n",
    "      },\n",
    "      \"minItems\": 3,\n",
    "      \"maxItems\": 3\n",
    "    },\n",
    "    \"moves\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"The sequence of moves made in the game, each representing a single placement.\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"player\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"Alice\", \"Player\"],\n",
    "            \"description\": \"The player who made the move.\"\n",
    "          },\n",
    "          \"row\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 2,\n",
    "            \"description\": \"The row index (0-2) where the player made the move.\"\n",
    "          },\n",
    "          \"col\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 2,\n",
    "            \"description\": \"The column index (0-2) where the player made the move.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"player\", \"row\", \"col\"]\n",
    "      }\n",
    "    },\n",
    "    \"current_player\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"Alice\", \"Player\"],\n",
    "      \"description\": \"Indicates who's turn it is to play.\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"board\", \"moves\", \"current_player\"]\n",
    "}'''\n",
    "\n",
    "cand1 = '''{\n",
    "  \"board\": [\n",
    "    [null, null, \"X\"],\n",
    "    [null, \"O\", \"X\"],\n",
    "    [\"O\", null, \"O\"]\n",
    "  ],\n",
    "  \"moves\": [\n",
    "    { \"player\": \"Alice\", \"row\": 0, \"col\": 2 },\n",
    "    { \"player\": \"Player\", \"row\": 2, \"col\": 2 },\n",
    "    { \"player\": \"Alice\", \"row\": 1, \"col\": 1 },\n",
    "    { \"player\": \"Player\", \"row\": 1, \"col\": 0 },\n",
    "    { \"player\": \"Alice\", \"row\": 0, \"col\": 0 }\n",
    "  ],\n",
    "  \"current_player\": \"Player\"\n",
    "}'''\n",
    "\n",
    "obs1 = ctx['observation1']\n",
    "\n",
    "\n",
    "prompt = f'''I want to use this representation to carefully formalize specific problems. The representation uses this schema:\n",
    "{rep}\n",
    "\n",
    "For the specific problem:\n",
    "```\n",
    "{obs1}\n",
    "```\n",
    "\n",
    "The corresponding representation I came up with is:\n",
    "```json\n",
    "{cand1}\n",
    "```\n",
    "Take a careful look, and if you find any mistakes, please correct them by providing a JSON block with the corrected representation. If you are sure the representation is correct, just say \"yes\".'''\n",
    "\n",
    "prompt = f'''I want to use this representation to carefully formalize specific problems. The representation uses this schema:\n",
    "{rep}\n",
    "\n",
    "For the specific problem:\n",
    "```\n",
    "{obs1}\n",
    "```\n",
    "\n",
    "The corresponding representation I came up with is:\n",
    "```json\n",
    "{cand1}\n",
    "```\n",
    "Take a careful look, and if you find any mistakes, please correct them by providing a JSON block with the corrected representation. If you are sure the representation is correct, just say \"yes\".'''\n",
    "\n",
    "prompt = f'''Rephrase the following problem specification in several ways (wrapping each into a markdown code block). Crucially, make sure that all the rephrasings are equivalent, meaning they describe the same problem, but use different wording or structure.\n",
    "\n",
    "```\n",
    "{obs1}\n",
    "```\n",
    "'''\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90350f1a35e7ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrep = json.loads(rep)\n",
    "# jrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8471fd52b9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noisy = [\"Alice and I are playing a game on a 3x3 grid. Alice's first move was to the cell in the middle row, right column.  I then played in the bottom row, right column. Alice responded by taking the cell in the bottom row, middle column, and I countered with the middle row, left column. Finally, Alice placed her mark in the top-right corner.\", \"The game began with Alice playing at (2,3). I then moved to (3,3). Alice followed up by playing at (3,2), and I responded with (2,1). Alice’s last move was to (1,3).\", \"Player Alice made the first move at the position immediately to the left of the right edge in the center row. Player I responded by claiming the rightmost position in the bottom row. Alice then occupied the center position in the bottom row. I countered by taking the position immediately to the right of the left edge in the middle row. Finally, Alice played in the top-right corner.\", \"Let's track the game state. Alice's moves were: (2,3), (3,2), (1,3). My moves were: (3,3), (2,1). This represents the sequence of plays so far.\", '''The game progressed as follows:\n",
    "1. Alice: Middle-right\n",
    "2. I: Bottom-right\n",
    "3. Alice: Bottom-middle\n",
    "4. I: Middle-left\n",
    "5. Alice: Top-right''', \"The initial moves in this game are as follows: Alice played to her second choice on the rightmost column, then I played to my second choice on the bottom row, followed by Alice taking the middle of the bottom row, I took the middle-left, and Alice's last play was in the top-right corner.\" ]\n",
    "\n",
    "noisy_obs_str = '\\n\\n'.join([f'```\\n{obs}\\n```' for i, obs in enumerate(noisy)])\n",
    "\n",
    "prompt = f'''Using the following schema, carefully formalize the problem described below. The schema is as follows:\n",
    "{rep}\n",
    "\n",
    "Here are several (mostly equivalent) ways to describe the problem:\n",
    "\n",
    "{noisy_obs_str}\n",
    "\n",
    "Note that although the descriptions vary, they all refer to a description of the same problem, so you should only respond with a single JSON block that captures the essence of the problem as described in the schema. Take care to faithfully represent every aspect of the problem to subsequently solve a reasoning tasks. If minor details conflict between the descriptions, choose the most common interpretation or the one that best fits the schema.\n",
    "'''\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e3eb407e7db67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957240fce564c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Use the following schema to carefully formalize the problem described below. The schema is as follows:\n",
    "{rep}\n",
    "\n",
    "For this problem:\n",
    "```\n",
    "{nx}\n",
    "```\n",
    "'''\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76df91e46585ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzs = [client.get_response(prompt.format(rep=rep, nx=n), grammar=jrep, temperature=1.)\n",
    "\t   \t\tfor n in tqdm(noisy)]\n",
    "len(nzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86a23624c373c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = []\n",
    "dats = []\n",
    "for nz in nzs:\n",
    "\tdat = json.loads(nz)\n",
    "\tdats.append(dat)\n",
    "\tboards.append(dat['board'])\n",
    "\tprint(dat)\n",
    "\tprint('---'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a965f6b991af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead8770dd605419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdiff import DeepDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9671387aae8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = DeepDiff(dats[0], dats[1], ignore_order=False)\n",
    "print(diff.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8899afd61b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsondiff import diff\n",
    "json_diff = diff(dats[0], dats[1])\n",
    "\n",
    "print(json_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519737be5c9dd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dats[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445285c363a182b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc436a64535e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = '''As the adventurer moved along the trail that twisted around the Lonely Mountain, it bent out of sight to the southeast and southwest. The elevation here was higher than to the south, providing a majestic view of the mountain's peak, veiled in a perpetual shroud of clouds. Unfortunately, no visible path from this vantage point led up the mountain.\\n\\nContinuing the journey, the adventurer arrived at the trail head on the northeast side of the Lonely Mountain. The narrow path snaked through rolling hills. To one side, a sign stood firmly, with a winding path disappearing into the thick undergrowth to the northeast. The trail itself stretched onward to the southeast.\\n\\nThe trail eventually concluded at Shady Brook, marked by the remnants of a ruined stone foundation-the Old Lingolf House. A small brook meandered lazily by, its gentle flow a contrast to the stillness of the abandoned site. The sun had just climbed above the hills, spilling light over the landscape.\\n\\nFeeling the weight of the journey, the adventurer filled a jug with water from the brook, quenching both thirst and preparing for the road ahead.\\n\\nReturning to the trail head, the path was as familiar as it was unwelcoming, flanked by the same rolling hills and the sign that pointed toward the thick undergrowth. The adventurer pressed on, reaching the Eastern Fork where multiple paths diverged around the base of the Lonely Mountain and a smaller path led eastward.\\n\\nThe road soon led into a small village on the outskirts, with the Lonely Mountain towering ominously in the background. The village path split to the northeast, but no path seemed to climb the mountain directly.\\n\\nEntering the deserted village revealed echoes of the past. This was once a bustling place where peasants, merchants, and artisans thrived. Now, it was silent except for the smoke rising from a decrepit hovel to the south. The path through the village led from southwest to northeast, and a less-trodden trail headed north up the mountain.\\n\\nInside the hovel, the air was thick with smoke and the stench of chaos. A pile of rags moved near a bubbling pot, revealing a gnarled hand stirring the contents. The rags belonged to a withered crone who eyed the adventurer with a piercing gaze. \\\"I should have thought they would send someone more... more...\\\" She cackled unsettlingly, revealing that everyone had fled from an impending storm in the east. \\\"Take this and begone!\\\" With a mystical gesture, she thrust a scroll into the adventurer's hands before pushing them out the door.\\n\\nBack in the open air, the adventurer unfurled the scroll, which revealed the \\\"rezrov spell\\\" capable of opening even locked or enchanted objects. With a sense of urgency, the spell was transcribed into the adventurer's spell book, which glowed with an ethereal light as the words were etched permanently into its pages. The scroll itself vanished in a whisper of magic as the last word was copied.\\n\\nThe journey resumed, leading back through the village outskirts and on to the Eastern Fork. The paths here were familiar, yet held new promise with the power of the newly acquired spell. The adventurer then ventured onto the Western Road, which wended its way through dark, rolling hills. To the west, a high mountain loomed; to the east, a dark castle with towering spires awaited.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223bca0eb6d2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''You are a Senior Data Architect specializing in knowledge representation. Your objective is to analyze a sample of unstructured narrative text and design a robust, task-agnostic JSON schema to model its content.\n",
    "\n",
    "This schema will be the blueprint for converting similar narrative texts into a structured format. The ultimate goal is to support downstream AI tasks such as pathfinding, state tracking, and answering questions about the environment, its characters, and its items.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "1.  **Analyze the Example Text:** Read the provided text to understand the types of entities and relationships that need to be represented. Pay close attention to:\n",
    "\n",
    "      * **Locations:** Distinct places the character can be.\n",
    "      * **Connections:** Paths, roads, or movements between locations, including their direction.\n",
    "      * **Entities:** Interactive or notable items and characters.\n",
    "      * **State:** Information that changes, such as the player's inventory, learned knowledge, or environmental conditions.\n",
    "\n",
    "2.  **Design the Schema:** Based on your analysis, create a generic JSON schema. The schema should:\n",
    "\n",
    "      * Represent the environment as a navigable graph (i.e., with nodes and edges).\n",
    "      * Be comprehensive enough to capture all the entity types you identified.\n",
    "      * Use a system of unique IDs to create stable references between different parts of the data (e.g., connecting a path to its destination location).\n",
    "      * Be self-documenting. Use the `\"description\"` field within the schema to explain the purpose of each property.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "Your final output must be **only the JSON schema itself**. Do not generate the populated JSON data for the example text.\n",
    "\n",
    "-----\n",
    "\n",
    "**Analyze the following example text to inform your schema design:**\n",
    "\n",
    "```\n",
    "As the adventurer moved along the trail that twisted around the Lonely Mountain, it bent out of sight to the southeast and southwest. The elevation here was higher than to the south, providing a majestic view of the mountain's peak, veiled in a perpetual shroud of clouds. Unfortunately, no visible path from this vantage point led up the mountain.\\n\\nContinuing the journey, the adventurer arrived at the trail head on the northeast side of the Lonely Mountain. The narrow path snaked through rolling hills. To one side, a sign stood firmly, with a winding path disappearing into the thick undergrowth to the northeast. The trail itself stretched onward to the southeast.\\n\\nThe trail eventually concluded at Shady Brook, marked by the remnants of a ruined stone foundation-the Old Lingolf House. A small brook meandered lazily by, its gentle flow a contrast to the stillness of the abandoned site. The sun had just climbed above the hills, spilling light over the landscape.\\n\\nFeeling the weight of the journey, the adventurer filled a jug with water from the brook, quenching both thirst and preparing for the road ahead.\\n\\nReturning to the trail head, the path was as familiar as it was unwelcoming, flanked by the same rolling hills and the sign that pointed toward the thick undergrowth. The adventurer pressed on, reaching the Eastern Fork where multiple paths diverged around the base of the Lonely Mountain and a smaller path led eastward.\\n\\nThe road soon led into a small village on the outskirts, with the Lonely Mountain towering ominously in the background. The village path split to the northeast, but no path seemed to climb the mountain directly.\\n\\nEntering the deserted village revealed echoes of the past. This was once a bustling place where peasants, merchants, and artisans thrived. Now, it was silent except for the smoke rising from a decrepit hovel to the south. The path through the village led from southwest to northeast, and a less-trodden trail headed north up the mountain.\\n\\nInside the hovel, the air was thick with smoke and the stench of chaos. A pile of rags moved near a bubbling pot, revealing a gnarled hand stirring the contents. The rags belonged to a withered crone who eyed the adventurer with a piercing gaze. \\\"I should have thought they would send someone more... more...\\\" She cackled unsettlingly, revealing that everyone had fled from an impending storm in the east. \\\"Take this and begone!\\\" With a mystical gesture, she thrust a scroll into the adventurer's hands before pushing them out the door.\\n\\nBack in the open air, the adventurer unfurled the scroll, which revealed the \\\"rezrov spell\\\" capable of opening even locked or enchanted objects. With a sense of urgency, the spell was transcribed into the adventurer's spell book, which glowed with an ethereal light as the words were etched permanently into its pages. The scroll itself vanished in a whisper of magic as the last word was copied.\\n\\nThe journey resumed, leading back through the village outskirts and on to the Eastern Fork. The paths here were familiar, yet held new promise with the power of the newly acquired spell. The adventurer then ventured onto the Western Road, which wended its way through dark, rolling hills. To the west, a high mountain loomed; to the east, a dark castle with towering spires awaited.\n",
    "```\n",
    "\n",
    "-----'''\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe39e8ace2e932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ludwig.chess import ChessPuzzle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2bd971b8057125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:12:18.106251Z",
     "start_time": "2025-08-05T10:12:18.101108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['puzzle_id', 'fen', 'player', 'legal', 'num_legal_moves', 'question', 'rationale', 'answer', 'system', 'task'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "task = ChessPuzzle(obs_rep='active')\n",
    "task.prepare()\n",
    "\n",
    "prob = task.ask_dev(0)\n",
    "prob.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3739a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White just played a2a7. Given the resulting board position:\n",
      "\n",
      "+---+---+---+---+---+---+---+---+\n",
      "| R |   |   | K |   |   |   | Q | 1\n",
      "+---+---+---+---+---+---+---+---+\n",
      "|   | P | P |   | N | P |   |   | 2\n",
      "+---+---+---+---+---+---+---+---+\n",
      "| P |   |   | P |   |   |   |   | 3\n",
      "+---+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |   | 4\n",
      "+---+---+---+---+---+---+---+---+\n",
      "|   |   |   | r | p |   |   |   | 5\n",
      "+---+---+---+---+---+---+---+---+\n",
      "|   | p | q |   |   | b |   |   | 6\n",
      "+---+---+---+---+---+---+---+---+\n",
      "| p |   | p |   |   |   | p | R | 7\n",
      "+---+---+---+---+---+---+---+---+\n",
      "|   | k |   |   |   |   |   | r | 8\n",
      "+---+---+---+---+---+---+---+---+\n",
      "  h   g   f   e   d   c   b   a\n",
      "\n",
      "\n",
      "(where uppercase letters are white pieces and lowercase letters are black pieces)\n",
      "\n",
      "What is the best move for black? Answer using the UCI or SAN format.\n"
     ]
    }
   ],
   "source": [
    "print(prob['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d477998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0469b718bfc8143",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:14:03.177331Z",
     "start_time": "2025-08-05T10:14:03.173601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will solve the following task using a structured tree-search framework.\n",
      "\n",
      "**Task Description:**\n",
      "We're playing tic-tac-toe, and, given the current game state, I would like to know specifically whether or not I should play in the middle next.\n",
      "\n",
      "**Example Problem:**\n",
      "Alice started with the top left corner and I played the bottom-middle. She took the middle row left, so I responded with the top middle. Now Alice played at the right middle location.\n",
      "\n",
      "Your first task is to design an optimal state representation for this problem. The representation must be:\n",
      "1.  **High-Fidelity:** It must capture all details necessary to solve the task unambiguously.\n",
      "2.  **Efficient:** It should contain minimal redundancy and exclude irrelevant \"nuisance\" details.\n",
      "3.  **Conducive to Search:** The structure should make it easy to implement the search functions (`expand`, `extract`, `evaluate`).\n",
      "\n",
      "Define this representation as a JSON schema, including clear descriptions for each property. Enclose the final output in a ```json ... ``` block.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########\n",
    "\n",
    "task = TakeTheMiddle(obs_rep='moves')\n",
    "task.prepare()\n",
    "\n",
    "prob = task.ask_dev(0)\n",
    "\n",
    "task = \"We're playing tic-tac-toe, and, given the current game state, I would like to know specifically whether or not I should play in the middle next.\"\n",
    "\n",
    "obs1 = prob['observation']\n",
    "\n",
    "##########\n",
    "\n",
    "# task = ChessPuzzle(obs_rep='active')\n",
    "# task.prepare()\n",
    "\n",
    "# prob = task.ask_dev(0)\n",
    "\n",
    "# task = \"We're playing tic-tac-toe, and, given the current game state, I would like to know specifically whether or not I should play in the middle next.\"\n",
    "\n",
    "# obs1 = prob['observation']\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "prompt = f'''We will solve the following task using a structured tree-search framework.\n",
    "\n",
    "**Task Description:**\n",
    "{task}\n",
    "\n",
    "**Example Problem:**\n",
    "{obs1}\n",
    "\n",
    "Your first task is to design an optimal state representation for this problem. The representation must be:\n",
    "1.  **High-Fidelity:** It must capture all details necessary to solve the task unambiguously.\n",
    "2.  **Efficient:** It should contain minimal redundancy and exclude irrelevant \"nuisance\" details.\n",
    "3.  **Conducive to Search:** The structure should make it easy to implement the search functions (`expand`, `extract`, `evaluate`).\n",
    "\n",
    "Define this representation as a JSON schema, including clear descriptions for each property. Enclose the final output in a ```json ... ``` block.'''\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1480b7f36542ab2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:14:19.302272Z",
     "start_time": "2025-08-05T10:14:03.699357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: `max_tokens` cannot be None, setting to 2048 for now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$schema': 'http://json-schema.org/draft-07/schema#',\n",
       " 'title': 'Tic Tac Toe Game State',\n",
       " 'type': 'object',\n",
       " 'properties': {'board': {'type': 'array',\n",
       "   'items': {'type': 'array',\n",
       "    'items': {'type': 'string', 'enum': ['X', 'O', '']},\n",
       "    'minItems': 3,\n",
       "    'maxItems': 3},\n",
       "   'minItems': 3,\n",
       "   'maxItems': 3,\n",
       "   'description': \"A 3x3 array representing the game board. 'X' for player X's moves, 'O' for player O's moves, and '' for empty spaces.\"},\n",
       "  'turn': {'type': 'string',\n",
       "   'enum': ['X', 'O'],\n",
       "   'description': \"Whose turn it is. 'X' if it's player X's turn, 'O' if it's player O's turn.\"}},\n",
       " 'required': ['board', 'turn'],\n",
       " 'additionalProperties': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resp = client.get_response(prompt)\n",
    "chat = client.begin_chat(prompt)\n",
    "\n",
    "resp = client.step(chat)\n",
    "rep = json.loads(next(extract_code_blocks(chat[-1]['content'], 'json')))\n",
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b02c4bc591a80d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def is_valid_move(board, row, col):\n",
      "    \"\"\"Check if a move at position (row, col) is valid.\"\"\"\n",
      "    return board[row][col] == \"\"\n",
      "\n",
      "def create_next_state(state, row, col):\n",
      "    \"\"\"Create a new state by applying a move at position (row, col) to the current state.\"\"\"\n",
      "    new_board = [row[:] for row in state[\"board\"]]\n",
      "    new_board[row][col] = state[\"turn\"]\n",
      "    new_turn = \"O\" if state[\"turn\"] == \"X\" else \"X\"\n",
      "    return {\"board\": new_board, \"turn\": new_turn}\n",
      "\n",
      "def expand(state):\n",
      "    \"\"\"\n",
      "    Generate all valid next states from the given state.\n",
      "    \n",
      "    Args:\n",
      "    state (dict): The current state of the game, conforming to the schema.\n",
      "    \n",
      "    Returns:\n",
      "    list: A list of all valid next states.\n",
      "    \"\"\"\n",
      "    next_states = []\n",
      "    for row in range(3):\n",
      "        for col in range(3):\n",
      "            if is_valid_move(state[\"board\"], row, col):\n",
      "                next_states.append(create_next_state(state, row, col))\n",
      "    return next_states\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['__builtins__', 'is_valid_move', 'create_next_state', 'expand'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'''Now your task is to implement the `expand` function in Python. This function takes a single state object (conforming to the schema) and returns a list of all valid next states.\n",
    "\n",
    "The function should only contain the minimal logic necessary to generate the next states (i.e., the \"rules\" of the task). Do not include any recursion, search, or heuristic logic within this function.\n",
    "\n",
    "Provide the implementation as a Python function named `expand` inside a ```python ... ``` block. If you need helper functions, make sure they are defined within the same block so the block can stand alone.'''\n",
    "\n",
    "chat.append({'role': 'user', 'content': prompt})\n",
    "resp = client.step(chat)\n",
    "\n",
    "print(chat[-1]['content'])\n",
    "\n",
    "pycode = next(extract_code_blocks(chat[-1]['content'], 'python'))\n",
    "\n",
    "objs = {}\n",
    "exec(pycode, objs)\n",
    "expand_fn = objs.get('expand')\n",
    "\n",
    "objs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b957dbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__builtins__', 'is_valid_move', 'create_next_state', 'expand', 'is_winner', 'is_draw', 'extract'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'''Next, your task is to implement the `extract` function in Python. This function analyzes a search path to find results or decide if the path should be abandoned. Its signature and return values should be:\n",
    "-   **Input:** Either a single state or a list of states (a trajectory).\n",
    "-   **Returns `str`:** An extracted result or piece of information. Prune the search here. If the string is not empty, it indicates some useful information has been found to help solve the problem. \n",
    "-   **Returns `None`:** No result found yet. The search continues down this path.\n",
    "\n",
    "First, state whether a **state-based** or **trajectory-based** input is more suitable for this task and briefly explain why.\n",
    "\n",
    "Then, implement the `extract` function based on your choice. Provide the implementation inside a ```python ... ``` block. If you need helper functions, make sure they are defined within the same block so the block can stand alone.'''\n",
    "\n",
    "chat.append({'role': 'user', 'content': prompt})\n",
    "resp = client.step(chat)\n",
    "\n",
    "pycode = next(extract_code_blocks(chat[-1]['content'], 'python'))\n",
    "exec(pycode, objs)\n",
    "extract_fn = objs.get('extract')\n",
    "# print(chat[-1]['content'])\n",
    "objs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df1c1e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A heuristic is necessary for this task. Although the search space of a tic-tac-toe game is finite, it is still relatively large, with approximately 255,168 possible unique positions. Without a heuristic, the search could be inefficient, especially if the algorithm has to explore a significant portion of the search space before finding a solution.\n",
      "\n",
      "I will use a **Score-based** approach. This approach involves assigning a score to each state based on its desirability, with higher scores indicating more promising states. The score can be calculated based on various factors, such as the control of the center, the number of possible wins, and the blocking of the opponent's potential wins.\n",
      "\n",
      "In the context of the original problem, the goal is to determine whether playing in the middle next is a good move. The heuristic function can be designed to prioritize states where playing in the middle leads to a better position.\n",
      "\n",
      "```python\n",
      "def evaluate(state):\n",
      "    \"\"\"\n",
      "    Evaluate the desirability of a state, prioritizing playing in the middle.\n",
      "    \n",
      "    Args:\n",
      "    state (dict): The current state of the game.\n",
      "    \n",
      "    Returns:\n",
      "    int: A score indicating the desirability of the state.\n",
      "    \"\"\"\n",
      "    board = state[\"board\"]\n",
      "    turn = state[\"turn\"]\n",
      "    opponent = \"O\" if turn == \"X\" else \"X\"\n",
      "    score = 0\n",
      "    \n",
      "    # Prioritize playing in the middle\n",
      "    if board[1][1] == \"\":\n",
      "        score += 10\n",
      "    \n",
      "    # Control of the center is valuable\n",
      "    if board[1][1] == turn:\n",
      "        score += 5\n",
      "    \n",
      "    # Blocking the opponent's potential wins is good\n",
      "    for i in range(3):\n",
      "        if board[i][0] == board[i][1] == opponent and board[i][2] == \"\":\n",
      "            score -= 3\n",
      "        if board[0][i] == board[1][i] == opponent and board[2][i] == \"\":\n",
      "            score -= 3\n",
      "    if board[0][0] == board[1][1] == opponent and board[2][2] == \"\":\n",
      "        score -= 3\n",
      "    if board[0][2] == board[1][1] == opponent and board[2][0] == \"\":\n",
      "        score -= 3\n",
      "    \n",
      "    # Creating opportunities to win is good\n",
      "    for i in range(3):\n",
      "        if board[i][0] == board[i][1] == turn and board[i][2] == \"\":\n",
      "            score += 2\n",
      "        if board[0][i] == board[1][i] == turn and board[2][i] == \"\":\n",
      "            score += 2\n",
      "    if board[0][0] == board[1][1] == turn and board[2][2] == \"\":\n",
      "        score += 2\n",
      "    if board[0][2] == board[1][1] == turn and board[2][0] == \"\":\n",
      "        score += 2\n",
      "    \n",
      "    return score\n",
      "```\n",
      "\n",
      "This implementation provides a basic heuristic that prioritizes playing in the middle while considering other factors such as control of the center, blocking the opponent's potential wins, and creating opportunities to win. The scores assigned are arbitrary and can be adjusted based on the specific requirements of the game or the performance of the search algorithm.\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''To make the search more efficient, we may need a heuristic `evaluate` function.\n",
    "\n",
    "This function's goal is to guide the search by prioritizing more promising states to solve the problem.\n",
    "\n",
    "First, state whether a heuristic is necessary for this task.\n",
    "-   If not, explain why (e.g., the search space is small enough).\n",
    "-   If it is, explain your chosen approach (e.g., scoring individual states, or sorting a list of candidates) and implement the `evaluate` function.\n",
    "\n",
    "The two possible approaches are:\n",
    "1. **Score-based**: The function takes a single state and returns a score indicating its desirability. States with higher scores are considered and expanded first.\n",
    "2. **Comparison-based**: The function takes a list of states and sorts them in which the most promising states come first. The search will then expand states in this order.\n",
    "\n",
    "Provide your reasoning and, if applicable, the Python implementation inside a ```python ... ``` block. If you need helper functions, make sure they are defined within the same block so the block can stand alone.'''\n",
    "\n",
    "chat.append({'role': 'user', 'content': prompt})\n",
    "resp = client.step(chat)\n",
    "try:\n",
    "    pycode = next(extract_code_blocks(chat[-1]['content'], 'python'))\n",
    "    exec(pycode, objs)\n",
    "    evaluate_fn = objs.get('evaluate')\n",
    "except StopIteration:\n",
    "    evaluate_fn = None\n",
    "print(chat[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c75a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27f4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrings = ['score-based', 'comparison-based']\n",
    "pattern = r'\\b(?:' + '|'.join(re.escape(sub) for sub in substrings) + r')\\b'\n",
    "\n",
    "text = chat[-1]['content']\n",
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e563c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score-based\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''Just to confirm, did you select the **score-based** or **comparison-based** approach for the `evaluate` function? Please respond with only \"score-based\" or \"comparison-based\".'''\n",
    "chat.append({'role': 'user', 'content': prompt})\n",
    "resp = client.step(chat, grammar=substrings)\n",
    "print(chat[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bdee744742e6e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'board': [['X', 'X', 'O'], ['O', '', ''], ['', 'X', '']], 'turn': 'X'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'''Now try to formalize the following example problem using the schema you designed:\n",
    "\n",
    "** Example Problem: **\n",
    "```\n",
    "{obs1}\n",
    "```'''\n",
    "\n",
    "chat.append({'role': 'user', 'content': prompt})\n",
    "resp = client.step(chat, grammar=rep)\n",
    "z = json.loads(chat[-1]['content'])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2145f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'board': ['X', 'X', None, 'O', 'O', None, None, 'X', None],\n",
       "  'turn': 'O',\n",
       "  'is_terminal': False,\n",
       "  'winner': None},\n",
       " {'board': ['X', None, 'X', 'O', 'O', None, None, 'X', None],\n",
       "  'turn': 'O',\n",
       "  'is_terminal': False,\n",
       "  'winner': None},\n",
       " {'board': ['X', None, None, 'O', 'O', 'X', None, 'X', None],\n",
       "  'turn': 'O',\n",
       "  'is_terminal': False,\n",
       "  'winner': None},\n",
       " {'board': ['X', None, None, 'O', 'O', None, 'X', 'X', None],\n",
       "  'turn': 'O',\n",
       "  'is_terminal': False,\n",
       "  'winner': None},\n",
       " {'board': ['X', None, None, 'O', 'O', None, None, 'X', 'X'],\n",
       "  'turn': 'O',\n",
       "  'is_terminal': False,\n",
       "  'winner': None}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs['expand'](z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8b891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877a272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4affff3016b9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "del chat[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83ef22880eae2141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'We will solve the following task using a structured tree-search framework.\\n\\n**Task Description:**\\nWe\\'re playing tic-tac-toe, and, given the current game state, I would like to know specifically whether or not I should play in the middle next.\\n\\n**Example Problem:**\\nAlice started with the top left corner and I played the bottom-middle. She took the middle row left, so I responded with the top middle. Now Alice played at the right middle location.\\n\\nYour first task is to design an optimal state representation for this problem. The representation must be:\\n1.  **High-Fidelity:** It must capture all details necessary to solve the task unambiguously.\\n2.  **Efficient:** It should contain minimal redundancy and exclude irrelevant \"nuisance\" details.\\n3.  **Conducive to Search:** The structure should make it easy to implement the search functions (`expand`, `extract`, `evaluate`).\\n\\nDefine this representation as a JSON schema, including clear descriptions for each property. Enclose the final output in a ```json ... ``` block.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'To design an optimal state representation for the tic-tac-toe game that meets the criteria of being high-fidelity, efficient, and conducive to search, we need to capture the current state of the game board and whose turn it is. The representation should be simple, yet informative enough to allow for the computation of the next best move.\\n\\nHere\\'s a proposed JSON schema for the state representation:\\n\\n```json\\n{\\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n  \"title\": \"Tic Tac Toe Game State\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"board\": {\\n      \"type\": \"array\",\\n      \"items\": {\\n        \"type\": \"array\",\\n        \"items\": {\\n          \"type\": \"string\",\\n          \"enum\": [\"X\", \"O\", \"\"]\\n        },\\n        \"minItems\": 3,\\n        \"maxItems\": 3\\n      },\\n      \"minItems\": 3,\\n      \"maxItems\": 3,\\n      \"description\": \"A 3x3 array representing the game board. \\'X\\' for player X\\'s moves, \\'O\\' for player O\\'s moves, and \\'\\' for empty spaces.\"\\n    },\\n    \"turn\": {\\n      \"type\": \"string\",\\n      \"enum\": [\"X\", \"O\"],\\n      \"description\": \"Whose turn it is. \\'X\\' if it\\'s player X\\'s turn, \\'O\\' if it\\'s player O\\'s turn.\"\\n    }\\n  },\\n  \"required\": [\"board\", \"turn\"],\\n  \"additionalProperties\": false\\n}\\n```\\n\\nThis schema includes:\\n- **board**: A 3x3 array of strings, where each string can be \"X\", \"O\", or \"\". This represents the current state of the tic-tac-toe board, with \"X\" indicating a move by player X, \"O\" indicating a move by player O, and \"\" indicating an empty space.\\n- **turn**: A string indicating whose turn it is, either \"X\" for player X or \"O\" for player O.\\n\\nThis representation is:\\n- **High-Fidelity**: It captures the current state of the board and whose turn it is, which are all the details necessary to determine the next move.\\n- **Efficient**: It only includes the necessary information, avoiding redundancy and excluding irrelevant details such as the game\\'s history or the players\\' names.\\n- **Conducive to Search**: The simple and structured format makes it easy to implement search functions like `expand` (to generate next possible states), `extract` (to identify key features of the state), and `evaluate` (to assess the desirability of a state).'},\n",
       " {'role': 'user',\n",
       "  'content': 'Now your task is to implement the `expand` function in Python. This function takes a single state object (conforming to the schema) and returns a list of all valid next states.\\n\\nThe function should only contain the minimal logic necessary to generate the next states (i.e., the \"rules\" of the task). Do not include any recursion, search, or heuristic logic within this function.\\n\\nProvide the implementation as a Python function named `expand` inside a ```python ... ``` block. If you need helper functions, make sure they are defined within the same block so the block can stand alone.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '```python\\ndef is_valid_move(board, row, col):\\n    \"\"\"Check if a move at position (row, col) is valid.\"\"\"\\n    return board[row][col] == \"\"\\n\\ndef create_next_state(state, row, col):\\n    \"\"\"Create a new state by applying a move at position (row, col) to the current state.\"\"\"\\n    new_board = [row[:] for row in state[\"board\"]]\\n    new_board[row][col] = state[\"turn\"]\\n    new_turn = \"O\" if state[\"turn\"] == \"X\" else \"X\"\\n    return {\"board\": new_board, \"turn\": new_turn}\\n\\ndef expand(state):\\n    \"\"\"\\n    Generate all valid next states from the given state.\\n    \\n    Args:\\n    state (dict): The current state of the game, conforming to the schema.\\n    \\n    Returns:\\n    list: A list of all valid next states.\\n    \"\"\"\\n    next_states = []\\n    for row in range(3):\\n        for col in range(3):\\n            if is_valid_move(state[\"board\"], row, col):\\n                next_states.append(create_next_state(state, row, col))\\n    return next_states\\n```'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948f3fee57e9b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
