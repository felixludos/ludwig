{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:52:36.552671Z",
     "start_time": "2025-04-02T20:52:36.543491Z"
    }
   },
   "cell_type": "code",
   "source": "len(range(10,100))",
   "id": "bd87fded314c781b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:59:42.707148Z",
     "start_time": "2025-04-03T12:59:42.702592Z"
    }
   },
   "cell_type": "code",
   "source": "from pathlib import Path",
   "id": "a5bfa387fffbe985",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T12:59:52.559279Z",
     "start_time": "2025-04-03T12:59:52.553226Z"
    }
   },
   "cell_type": "code",
   "source": "Path('foo/bar').relative_to('foo')",
   "id": "62b67168b7d8883e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('bar')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "888c1b4a34c63bcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T18:24:22.648920Z",
     "start_time": "2025-04-03T18:24:22.618762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find what model is running on a vllm server\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "def get_vllm_model_info(server_url: str) -> Dict[str, Any]:\n",
    "\t\"\"\"\n",
    "\tGet the model information from a VLLM server.\n",
    "\n",
    "\tArgs:\n",
    "\t\tserver_url (str): The URL of the VLLM server.\n",
    "\n",
    "\tReturns:\n",
    "\t\tDict[str, Any]: A dictionary containing the model information.\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\tresponse = requests.get(f\"{server_url}/v1/models\")\n",
    "\t\tresponse.raise_for_status()  # Raise an error for bad responses\n",
    "\t\tmodel_info = response.json()\n",
    "\t\treturn model_info\n",
    "\texcept requests.RequestException as e:\n",
    "\t\tprint(f\"Error fetching model info: {e}\")\n",
    "\t\treturn {}\n",
    "\n",
    "info = get_vllm_model_info(\"http://localhost:8000\")\n",
    "info"
   ],
   "id": "426557828a2dc5a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'id': 'microsoft/Phi-4-multimodal-instruct',\n",
       "   'object': 'model',\n",
       "   'created': 1743704659,\n",
       "   'owned_by': 'vllm',\n",
       "   'root': 'microsoft/Phi-4-multimodal-instruct',\n",
       "   'parent': None,\n",
       "   'max_model_len': 65536,\n",
       "   'permission': [{'id': 'modelperm-97ec2978acaa401e8ae91ab95a623042',\n",
       "     'object': 'model_permission',\n",
       "     'created': 1743704659,\n",
       "     'allow_create_engine': False,\n",
       "     'allow_sampling': True,\n",
       "     'allow_logprobs': True,\n",
       "     'allow_search_indices': False,\n",
       "     'allow_view': True,\n",
       "     'allow_fine_tuning': False,\n",
       "     'organization': '*',\n",
       "     'group': None,\n",
       "     'is_blocking': False}]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:18:41.908574Z",
     "start_time": "2025-04-03T21:18:41.901721Z"
    }
   },
   "cell_type": "code",
   "source": "info['data'][0]['id']",
   "id": "bc61c4cbc983c28f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'microsoft/Phi-4-multimodal-instruct'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T19:48:15.970278Z",
     "start_time": "2025-04-03T19:48:14.217392Z"
    }
   },
   "cell_type": "code",
   "source": "import openai",
   "id": "81e71e759fae9eca",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T19:48:58.699132Z",
     "start_time": "2025-04-03T19:48:58.572240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai.ChatCompletion.create(\n",
    "\t  model=\"microsoft/Phi-4-multimodal-instruct\",\n",
    "\n",
    "  messages=[\n",
    "\t\t{\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "\t]\n",
    "\t# temperature=0,\n",
    ")"
   ],
   "id": "8e2b48a913008b26",
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAPIRemovedInV1\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m\t  \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicrosoft/Phi-4-multimodal-instruct\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m  \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHello!\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m\t\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m\t\u001B[49m\u001B[38;5;66;43;03m# temperature=0,\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001B[0m, in \u001B[0;36mAPIRemovedInV1Proxy.__call__\u001B[1;34m(self, *_args, **_kwargs)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m_args: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIRemovedInV1(symbol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_symbol)\n",
      "\u001B[1;31mAPIRemovedInV1\u001B[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T19:53:56.227515Z",
     "start_time": "2025-04-03T19:53:55.379881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "completion = client.completions.create(model=\"microsoft/Phi-4-multimodal-instruct\",\n",
    "                                      prompt=\"Complete the sentence: San Francisco is a\")\n",
    "print(\"Completion result:\", completion)"
   ],
   "id": "2ca534ede83055a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion result: Completion(id='cmpl-9f402c1a31004efdba6df3c46bfb81ec', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' city in _____. Multiple choice:\\na. California\\nb. New York\\n', stop_reason=None, prompt_logprobs=None)], created=1743710032, model='microsoft/Phi-4-multimodal-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=8, total_tokens=24, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T19:56:52.946124Z",
     "start_time": "2025-04-03T19:56:48.380473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resp = client.chat.completions.create(model=\"microsoft/Phi-4-multimodal-instruct\",\n",
    "                                      messages=[{'role':'user', 'content': 'Tell me a short joke.'}])\n",
    "resp"
   ],
   "id": "331e6e144664ef62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-db823bf039a64989b0514e7dd29c52e9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why was the math book sad?\\n\\nBecause it had too many problems! 😄', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=200020)], created=1743710209, model='microsoft/Phi-4-multimodal-instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=9, total_tokens=26, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T19:59:41.280068Z",
     "start_time": "2025-04-03T19:59:41.239203Z"
    }
   },
   "cell_type": "code",
   "source": "resp.choices[0].completion_tokens",
   "id": "eb4df55a51ebd511",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Choice' object has no attribute 'completion_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pydantic\\main.py:883\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    882\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 883\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpydantic_extra\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'completion_tokens'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mresp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletion_tokens\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pydantic\\main.py:885\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    883\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pydantic_extra[item]\n\u001B[0;32m    884\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m--> 885\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, item):\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Choice' object has no attribute 'completion_tokens'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T20:00:15.883926Z",
     "start_time": "2025-04-03T20:00:15.870279Z"
    }
   },
   "cell_type": "code",
   "source": "resp.usage",
   "id": "c46412b03d49e4b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=17, prompt_tokens=9, total_tokens=26, completion_tokens_details=None, prompt_tokens_details=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:39:51.843241Z",
     "start_time": "2025-04-03T21:39:51.801120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stream = client.chat.completions.create(model=\"microsoft/Phi-4-multimodal-instruct\", stream=True,\n",
    "\t\t\t\t\t\t\t\t\t\tstream_options={\"include_usage\": True},\n",
    "                                      messages=[{'role':'user', 'content': 'Tell me a short joke.'}])\n"
   ],
   "id": "148764cd21e66292",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:39:52.302980Z",
     "start_time": "2025-04-03T21:39:52.296597Z"
    }
   },
   "cell_type": "code",
   "source": "stream",
   "id": "557c01de99969331",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x20b1f75b710>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:39:53.523271Z",
     "start_time": "2025-04-03T21:39:53.518074Z"
    }
   },
   "cell_type": "code",
   "source": "chunk = next(stream)",
   "id": "6bdd4e14b24dc4f9",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:39:54.459504Z",
     "start_time": "2025-04-03T21:39:54.453601Z"
    }
   },
   "cell_type": "code",
   "source": "chunk.choices[0].delta",
   "id": "e68974c9fb20f2c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T20:28:08.317578Z",
     "start_time": "2025-04-03T20:28:08.310036Z"
    }
   },
   "cell_type": "code",
   "source": "type(stream)",
   "id": "b25c1c3b092ecfef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.Stream"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T21:39:58.434744Z",
     "start_time": "2025-04-03T21:39:58.429697Z"
    }
   },
   "cell_type": "code",
   "source": "chunk.usage",
   "id": "2d8f2814dfec5e6d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efbd23daf489368f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "47b1f982575c26f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "11029fe591a323db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "312ffb39af53e777"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
